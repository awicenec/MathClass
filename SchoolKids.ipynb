{"cells":[{"metadata":{},"cell_type":"markdown","source":["# Using Python and Jupyter for Data Analysis"]},{"metadata":{},"cell_type":"markdown","source":["Welcome to the exciting world of Data Science! The environment you are in right now is what many professional Data Scientists are using to explore and analyse complex data sets. It is called Jupyter and we are using the environment with a programming language called Python. \n","\n","Jupyter is providing a whole ecosystem of tools, what we are specifically using here is a Jupyter Notebook. \n","\n","A Jupyter Notebook is a completely interactive, web-based environment in which you can use the programming language, in our case Python, in your browser. \n","\n","Usually you would use your own computer, but for this class we are using Jupyter in the cloud, more specifically we are using a service called Binder, which allows to build a stand-alone Jupyter server just for your notebooks and share them with others. There are many things going on behind the scenes to make this happen, but Binder itself is building the dedicated Jupyter server and the running it on the Google Cloud. "]},{"metadata":{},"cell_type":"markdown","source":["## Let's get started"]},{"metadata":{},"cell_type":"markdown","source":["A notebook consists of a vertical column of cells like the one this text is in. Cells are like paragraphs in a text, but they are 'active', can be executed and edited much more like cells in an Excel spreadsheet. Like in a spreadsheet you can move from one cell to the next using the cursor keys or the mouse and the green or blue box around the current cell indicates where you are. Easy!"]},{"metadata":{},"cell_type":"markdown","source":["There are two main kinds of cells, one is called 'Markdown', the other are Code cells, in our case for Python code. Markdown is for text. You can enter a cell by pressing 'Enter' or double clicking. You can exit a cell by pressing Esc. Once in a cell you can change the content, like in Excel. If you want to execute the cell you can press Shift+Enter (execute and go to next) or Control+Enter (just execute)."]},{"source":["Let's try a few simple code cells (remember that you have the whole Python language at your fingertips!):"],"cell_type":"markdown","metadata":{}},{"metadata":{"trusted":true},"cell_type":"code","source":["x = 14 * 3"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"tags":[]},"cell_type":"code","source":["y = 14**3 \n","print('x = {0}; y = {1}'.format(x, y))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["x < y"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["If you want to learn Python, there are myriads of resources available on the web..."]},{"metadata":{},"cell_type":"markdown","source":["## Now let's get to the data analysis:"]},{"metadata":{"tags":[]},"cell_type":"markdown","source":["### First we need to load a powerful library:\n","Libraries are software packages written for Python for specific purposes."]},{"metadata":{"trusted":true},"cell_type":"code","source":["import pandas as pd               # This is the workhorse for everything Data Science in Python"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### Read the data using Pandas:"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df = pd.read_csv('data/data1000.csv')  # That's just the CSV data you've received"],"execution_count":null,"outputs":[]},{"source":["The command above does not produce any output, but the result of reading the file is now contained in the variable *df*."],"cell_type":"markdown","metadata":{}},{"metadata":{"trusted":true},"cell_type":"markdown","source":["#### How does the data look like?"]},{"metadata":{},"cell_type":"markdown","source":["Just typing the variable name shows a summary of the content."]},{"metadata":{"trusted":true},"cell_type":"code","source":["df"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["As you can see the variable *'df'* contains something quite different from your usual Math variable! It contains the whole data set in a quite convenient form to deal with in a programming language.\n","\n","You can get the headings of the columns by 'asking' the variable:"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df.keys()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["There is a pretty strange column in there called *'Unnamed: 20'*. Let's examine what it contains:"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df['Unnamed: 20']"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Seems to contain just invalid numbers (NaN means *'Not a Number'*), but let's verify that:"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df['Unnamed: 20'].notnull().values.any()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["In words the line above means: Are there *any values* in the column *'Unnamed: 20'* that are *not null*?\n","The answer is *False*, which means there are no such values.\n","\n","As you can see there are functions for all kinds of use cases in Pandas...\n","\n","Also to answer the exactly opposite question:"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df['Unnamed: 20'].isnull().values.all()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Note the usage of *all()* here!"]},{"metadata":{},"cell_type":"markdown","source":["#### Create a histogram plot of reaction times of females and males"]},{"metadata":{},"cell_type":"markdown","source":["Now we will try to answer the question whether there is a significant difference between the measured reaction times of female and male students. \n","\n","To do this, we need to get the values separated by the *Gender* column. You can do this the hard way, but of course there is also a Pandas function to perform exactly that for you and even for the complete data set at once! This function is called *groupby* and takes the column name you want to use for grouping as an argument.\n","\n","Calling it naÃ®vely like this, results in a pretty strange output:"]},{"metadata":{"trusted":true},"cell_type":"code","source":["df.groupby('Gender')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["This is plain Python gibberish, but it reveals that the result is actually something that is called an *object*. Very often objects have quite a lot of functionality embedded in it. You can examine this by using the Python built-in function *dir*."]},{"metadata":{"trusted":true},"cell_type":"code","source":["dir(df.groupby('Gender'))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df.groupby('Gender').plot()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Some global settings used a lot below\n","GROUPBY = ['Favourite_physical_activity']   # dataset will be grouped by these columns\n","VALUE_COLUMN = 'Ageyears'   # the column used as a value (should be numerical)\n","X_TITLE = VALUE_COLUMN           # the title for the x-axis\n","Y_TITLE = GROUPBY                # the title for the y-axis\n","SCALED = True                    # normalized histograms or not"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_G = df.groupby(GROUPBY)       # perform the grouping"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_G.groups.keys()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# This is pretty powerful: it plots the histograms for all groups using a single command. The rest of the keywords are just to tidy things up a bit.\n","\n","ax = df_G[VALUE_COLUMN].plot.hist(figsize=(12,8), legend=True, alpha=0.5, density=SCALED)\n","_ = ax[-1].set_xlabel(X_TITLE)\n","_ = ax[-1].set_ylabel(Y_TITLE)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Now we are trying to deal with the 'outliers':"]},{"metadata":{},"cell_type":"markdown","source":["We need to do this for the groups separately:"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# This is assuming that we have just two groups:\n","df_f = df[VALUE_COLUMN].where(df['Gender'] == 'F')\n","df_m = df[VALUE_COLUMN].where(df['Gender'] == 'M')"],"execution_count":null,"outputs":[]},{"source":["Since we will use this a few times, we just define a couple of functions and use another library to help us with that job."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import scipy, scipy.stats                      # a big Python module for everything science data exploration"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def remove_outliers(s, low=None, high=None, index=False):\n","    \"\"\"\n","    Helper function to remove outliers above or below certain quantiles\n","    \"\"\"\n","    if not low:\n","        low = 0.25   # standard for outlier definition\n","    if not high:\n","        high = 1 - low\n","    iqr = scipy.stats.iqr(s, nan_policy='omit')\n","    if not index:\n","        return s[s.between(s.quantile(low) - 1.5 * iqr, s.quantile(high) + 1.5 * iqr)]\n","    else:\n","        return s.between(s.quantile(low) - 1.5 * iqr, s.quantile(high) + 1.5 * iqr)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def outlier_cutoff(s):  \n","    \"\"\"\n","    Helper function to get the IQR and standard quantile bounds.\n","    \"\"\"\n","    iqr = scipy.stats.iqr(s, nan_policy='omit')\n","    return {'iqr':iqr, 'lower bound': s.quantile(0.25)-1.5*iqr, 'upper bound': s.quantile(0.75)+1.5*iqr}"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["df_fc = remove_outliers(df_f, low=0.25)\n","df_mc = remove_outliers(df_m, low=0.25)\n","df_f = df[VALUE_COLUMN].where(df['Gender'] == 'F')"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt   # very powerful python plotting library"]},{"metadata":{},"cell_type":"markdown","source":["### we can plot without even knowing the number or name of the groups"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# get the actual group names\n","group_names = list(df_G.groups.keys()) \n","\n","quant = 0.25  # quantile to remove outliers \n","\n","fig = plt.figure(figsize=[12,8])  # start a new figure with a certain size\n","ax = fig.gca()                    # get the figure axes\n","\n","# remove outliers in first group\n","G0_cleaned = remove_outliers(df_G.get_group(group_names[0])[VALUE_COLUMN], low=quant)\n","\n","# do the plot for first plot\n","G0_cleaned.plot.hist(ax=ax, figsize=(12,8), legend=True, alpha=0.5, density=SCALED)\n","\n","# create a subplots for all remaining groups\n","for g in group_names[1:]:  \n","    # sometimes the group keys have NaN values: Not good, because histogram will fail!\n","    # we will just omit that subplot.\n","    try: \n","        g_cleaned = remove_outliers(df_G.get_group(g)[VALUE_COLUMN], low=quant)\n","        g_cleaned.plot.hist(ax=ax, figsize=(12,8), legend=True, alpha=0.5, density=SCALED)\n","    except: \n","        next\n","\n","# put the group names in the legend and set the axis labels\n","_ = ax.legend(group_names)\n","_ = ax.set_xlabel(X_TITLE)\n","_ = ax.set_ylabel('Frequency')\n","\n","# Change y axis label if the histogram is normalized.\n","if SCALED: ax.set_ylabel('Normalized Frequency')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Let's do something a bit more exciting, also showing the power of matplotlib."]},{"metadata":{"trusted":true},"cell_type":"code","source":["fig = plt.figure(figsize=[12,8])  # start a new figure with a certain size\n","ax = fig.gca()                    # get the figure axes\n","\n","_ = df.boxplot(ax=ax, by=GROUPBY, column=VALUE_COLUMN, vert=False)\n","_ = ax.set_xlabel(X_TITLE)\n","_ = ax.set_ylabel(Y_TITLE)\n","_ = ax.set_title('')"],"execution_count":null,"outputs":[]},{"source":["There is an interesting kind of plot, which shows something similar to the boxplot above, but even more additional information. That kind of plot is called a *violin plot* and is not available in matplotlib. Thus we load yet another library to enable this."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import seaborn as sns             # high level plots"]},{"source":["The library allows a very flexible configuration of the plots and thus the commands look a bit daunting. The way this is implemented below also allows for more than two groups to be shown correctly (think about more groups than just female and male). We will explore this afterwards."],"cell_type":"markdown","metadata":{}},{"metadata":{"trusted":true},"cell_type":"code","source":["fig = plt.figure(figsize=[12,8])  # start a new figure with a certain size\n","ax = fig.gca()                    # get the figure axes\n","\n","dfc = df\n","# dfc = df.loc[df.Reaction_time <= 1.5]\n","\n","if len(GROUPBY) == 2:\n","    _ = sns.violinplot(data=dfc, x=GROUPBY[0], y=VALUE_COLUMN, hue=GROUPBY[1], split=True, inner=\"quartile\", bw=0.25, cut=0)\n","else:\n","    dfc['dummy'] = 'A'\n","    _ = sns.violinplot(data=dfc, x='dummy', y=VALUE_COLUMN, hue=GROUPBY[0], width=0.25, split=False, inner=\"quartile\", bw=0.25, cut=0)\n","    _ = ax.set_xlabel(X_TITLE)\n","    _ = ax.set_xticklabels('')\n","_ = ax.set_ylabel(Y_TITLE)\n","_ = ax.set_title('')"],"execution_count":null,"outputs":[]},{"source":["The plot shows many things in one go:\n","\n","1. Both groups side-by-side (female blue, male orange)\n","2. The smoothed distributions\n","3. Median, lower and upper quartiles\n","4. The tails as well.\n","\n","... and it even looks quite pleasing, which is an important aspect for plots."],"cell_type":"markdown","metadata":{}},{"source":["## Examine different hypothesis:\n","Arm span of a person is approximately the same as the person's height.\n","\n","That would mean that they values plotted against each other should approximately follow a line with a gradient of 1. \n","\n","Remember the equation y = m * x + c ?? "],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_COLUMN = 'Height'\n","Y_COLUMN = 'Arm_Span'"]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":["fig = plt.figure(figsize=[12,8])  # start a new figure with a certain size\n","ax = fig.gca()                    # get the figure axes\n","# ax.set_xlim([100, 230])\n","# ax.set_ylim([100, 230])\n","ax = sns.regplot(ax=ax, x=df[X_COLUMN],y=df[Y_COLUMN])"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure(figsize=[12,2])  # start a new figure with a certain size\n","ax = fig.gca()                    # get the figure axes\n","_ = sns.residplot(x=df[X_COLUMN],y=df[Y_COLUMN])"]},{"metadata":{},"cell_type":"markdown","source":["### Same but using a feature rich stats library"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import statsmodels.api as sm      # a Python statistics module "]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":["X = sm.add_constant(df[X_COLUMN])  # make sure the algorithm has enough degrees of freedom\n","Y = df[Y_COLUMN]                 # use Arm_Span; Hypothesis: Arm_Span ~= Height\n","model = sm.OLS(Y, X).fit()         # Perform the fit\n","print(model.summary())             # show fitting summary"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### R-squared is 0.508, a reasonable fit, but the data has quite a few outliers\n","\n","### Cleanup outliers:"]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":["out = model.outlier_test()     # check for outliers\n","\n","select = abs(out['student_resid']) <= 2.  \n","\n","yfit_df = pd.DataFrame(model.fittedvalues)  # the fitted values (on the line)\n","\n","Xdf = pd.DataFrame(X.values[:,1])\n","Ydf = pd.DataFrame(Y)\n","Xclean = Xdf.loc[(select).values].values # remove all X coords with a residual > 2\n","Yclean = Ydf.loc[(select).values].values # remove all Y coords with a residual > 2\n","yfit_clean = yfit_df.loc[(select).values].values\n","\n","print(\"{0} outliers identified:\".format(len(df[X_COLUMN]) - len(Xclean)))\n","\n","# perform the fit without outliers\n","Xfit = sm.add_constant(Xclean)\n","cfit = sm.OLS(Yclean, Xfit).fit()\n","print(\"Fit results without outliers:\")\n","print(cfit.summary())"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### R-squared is now 0.791: quite an improvement!"]},{"metadata":{"trusted":true},"cell_type":"code","source":["fig = plt.figure(figsize=[12,8])  # start a new figure with a certain size\n","ax = fig.gca()                    # get the figure axes\n","\n","_ = plt.scatter(df[X_COLUMN], Y)                                # points with outliers\n","_ = plt.plot(df[X_COLUMN], model.fittedvalues, color=\"red\")     # fit line with outliers\n","_ = plt.scatter(Xclean, Yclean, color=\"orange\")                 # points without outliers\n","_ = plt.plot(Xclean, cfit.fittedvalues, color=\"green\")          # fit line without outliers\n","ax.set_xlabel(X_COLUMN)\n","ax.set_ylabel(Y_COLUMN)\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":["print(outlier_cutoff(df_f))"],"execution_count":null,"outputs":[]}],"metadata":{"hide_input":false,"kernelspec":{"name":"Python 3.8.5 64-bit","display_name":"Python 3.8.5 64-bit","metadata":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"language_info":{"name":"python","version":"3.8.5-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}